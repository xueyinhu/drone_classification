x = [
    '注意力的重要性已经被广泛的研究过，我们希望能通过注意力机制来增强特征图的表现能力，\
        即激活重要的特征，抑制非必要的特征。',
    '我们设计了一个简单有效的前馈卷积神经网络注意力模块，\
        顺序推导出三个独立维度的注意力图，\
        然后将注意力映射图乘到输入或中间特征上实现自适应特征激活。',
    'P2P attention module 是一个非常轻量级的通用模块，\
        可以无缝继承到任何 CNN 架构中而开销可以忽略不计。',
]



